{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "\n",
    "# LendingClub Project \n",
    "*the project is based on pieriandata DataScience course.*\n",
    "\n",
    "\n",
    "In the second part of LendingClub project, we will take a look at generalzed-stacking models. If you haven't seen the first one, you can access it by clicking on the [LendingClub: Part1 - Basic Analysis and Modeling](https://github.com/PatrykRadon/LendingClub-Project/blob/master/LendingClub:%20Part1%20-%20Basic%20Analysis%20and%20Modeling.ipynb) link.\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we will try to lean even further towards predicting a non-paid loans (as the more finacially-critical aspect), and at the same time we will try to improve on paid ones. Still, due to a limited computational capacities, this is only a presentation of how far we could potentilly take this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without further ado - lets do some imports and get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcdf = pd.read_csv('dummy_loan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lcdf.drop('not.fully.paid',axis=1)\n",
    "y = lcdf['not.fully.paid']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "X_train_lay1, X_train_lay2, y_train_lay1, y_train_lay2 = train_test_split(X_train, y_train, test_size=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's stack some classifiers!\n",
    "\n",
    "In short, let's have some classifiers focus on predicting non-paid loans, and some generally doing the best they can to get as accurate as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "randf_biased_csf = RandomForestClassifier(n_estimators=4000, max_depth=7, class_weight={0: 1, 1: 2})\n",
    "randf_csf = RandomForestClassifier(n_estimators=4000, max_depth=4)\n",
    "\n",
    "xgb_csf = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=4000,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0.18,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27,\n",
    " reg_alpha= 1)\n",
    "\n",
    "nb_csf = GaussianNB()\n",
    "\n",
    "knn1_csf = KNeighborsClassifier(n_neighbors=2)\n",
    "knn2_csf = KNeighborsClassifier(n_neighbors=4)\n",
    "knn3_csf = KNeighborsClassifier(n_neighbors=8)\n",
    "knn4_csf = KNeighborsClassifier(n_neighbors=16)\n",
    "knn5_csf = KNeighborsClassifier(n_neighbors=32)\n",
    "knn6_csf = KNeighborsClassifier(n_neighbors=64)\n",
    "\n",
    "lreg_csf = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "lreg_biased_csf = make_pipeline(StandardScaler(),LogisticRegression(class_weight={0: 1, 1: 2}))\n",
    "\n",
    "svc_csf = make_pipeline(StandardScaler(),SVC(kernel='rbf', probability=True))\n",
    "svc_biased_csf = make_pipeline(StandardScaler(),SVC(kernel='rbf', probability=True, class_weight={0: 1, 1: 2}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all, lets see how our model performs without focusing too much on the non-paid loans.**\n",
    "    \n",
    "  For this purpose, we will need an unbiased first-layer estimator. In our case, we will use XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_l1_csf = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=3000,\n",
    " max_depth=4,\n",
    " min_child_weight=1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators1 = [('xgb',xgb_csf),\n",
    "             ('randf', randf_csf),\n",
    "             ('nb',nb_csf),\n",
    "             ('knn1',knn1_csf),\n",
    "             ('knn2',knn2_csf),\n",
    "             ('knn3',knn3_csf),\n",
    "             ('knn4',knn4_csf),\n",
    "             ('knn5',knn5_csf),\n",
    "             ('knn6',knn6_csf),\n",
    "             ('svc',svc_csf),\n",
    "             ('lreg',lreg_csf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_csf1 = StackingClassifier(\n",
    "...     estimators=estimators1, final_estimator=xgb_l1_csf\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_model1 = stacked_csf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      2411\n",
      "           1       0.39      0.04      0.07       463\n",
      "\n",
      "    accuracy                           0.84      2874\n",
      "   macro avg       0.62      0.51      0.49      2874\n",
      "weighted avg       0.77      0.84      0.77      2874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =stacked_model1.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 (+/- 0.01) [XGBoost]\n",
      "Accuracy: 0.84 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.83 (+/- 0.01) [naive Bayes]\n",
      "Accuracy: 0.82 (+/- 0.01) [Knn2]\n",
      "Accuracy: 0.83 (+/- 0.00) [Knn4]\n",
      "Accuracy: 0.83 (+/- 0.00) [Knn8]\n",
      "Accuracy: 0.84 (+/- 0.00) [Knn16]\n",
      "Accuracy: 0.84 (+/- 0.00) [Knn32]\n",
      "Accuracy: 0.84 (+/- 0.00) [Knn64]\n",
      "Accuracy: 0.84 (+/- 0.00) [SVC]\n",
      "Accuracy: 0.84 (+/- 0.00) [Logistic Reggression]\n"
     ]
    }
   ],
   "source": [
    "for csf, label in zip([xgb_csf, randf_csf, nb_csf, knn1_csf, knn2_csf, knn3_csf, knn4_csf, knn5_csf, knn6_csf,svc_csf,lreg_csf], ['XGBoost', 'Random Forest', 'naive Bayes', 'Knn2', 'Knn4', 'Knn8','Knn16', 'Knn32', 'Knn64','SVC','Logistic Reggression']):\n",
    "...     scores = cross_val_score(csf, X_test, y_test, scoring='accuracy', cv=5)\n",
    "...     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First observations\n",
    "\n",
    "Well.. it is not worse, thats for sure. It performs roughly equally to our best tries from part 1. \n",
    "\n",
    "**But** that is not why we are here, what we want is to use the robustness and precision of XGBoost to compensate for estimators focused on catching the non-paid loans, while we try to bias towards them!\n",
    "\n",
    "So, lets get straight to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators2 = [('xgb',xgb_csf),\n",
    "             ('randf', randf_biased_csf),\n",
    "             ('nb',nb_csf),\n",
    "             ('knn1',knn1_csf),\n",
    "             ('knn2',knn2_csf),\n",
    "             ('knn3',knn3_csf),\n",
    "             ('knn4',knn4_csf),\n",
    "             ('knn5',knn5_csf),\n",
    "             ('knn6',knn6_csf),\n",
    "             ('svc',svc_biased_csf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_csf2 = StackingClassifier(\n",
    "...     estimators=estimators2, final_estimator=lreg_biased_csf\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model2 = stacked_csf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      2411\n",
      "           1       0.44      0.16      0.24       463\n",
      "\n",
      "    accuracy                           0.83      2874\n",
      "   macro avg       0.65      0.56      0.57      2874\n",
      "weighted avg       0.79      0.83      0.80      2874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =stacked_model2.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, here are the results of Random Forest from part 1:\n",
    "\n",
    "                   precision    recall  f1-score   support\n",
    "\n",
    "               0       0.86      0.94      0.90      2431\n",
    "               1       0.33      0.15      0.20       443\n",
    "\n",
    "        accuracy                           0.82      2874\n",
    "       macro avg       0.59      0.55      0.55      2874\n",
    "    weighted avg       0.78      0.82      0.79      2874"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!\n",
    "\n",
    "We have improved in every way possible! As shown, combining robust, flexible XGBoost with some biased estimators can provide us with the benefits of both! As a result we got more accurate, precise estimator that still does the task of focusing on more finacially-critical aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
